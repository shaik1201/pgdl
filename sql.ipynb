{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc6171-a93c-4fc5-bb8d-7f63daa2aab5",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import json, requests, time\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine('postgresql://postgres:argmax@pg:5432/postgres')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c6725",
   "metadata": {},
   "source": [
    "# Data\n",
    "Every time a user opens a mobile app, an auction is going on behind the scenes. The highest bidder gets to advertise his ad to the user.\n",
    "## Auctions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a63fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = 'SELECT * FROM auctions;'\n",
    "with engine.connect() as db_con:\n",
    "    big_df = pd.read_sql(sql_query, con=db_con)\n",
    "\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c86e9",
   "metadata": {},
   "source": [
    "## App Vectors table\n",
    "We've gathered the first few sentences from the app store description and embedded it with a [model](https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05408c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f'''\n",
    "SELECT\n",
    "    *\n",
    "FROM app_vectors\n",
    "'''\n",
    "has_embedding = False\n",
    "while not has_embedding:\n",
    "    with engine.connect() as db_con:\n",
    "        embeds_df = pd.read_sql(sql_query, con=db_con)\n",
    "    has_embedding = (~df[\"embedding\"].isna()).all()\n",
    "    if not has_embedding:\n",
    "        print(\"Waiting for embeddings...\")\n",
    "        time.sleep(15)\n",
    "\n",
    "embeds_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac0d2f",
   "metadata": {},
   "source": [
    "We can use the `<=>` operator to run vector search within the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79504473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vec = json.loads(df.embedding[0]) # get the first embedding\n",
    "print (\"Embedding size: {l}\".format(l=len(vec)))\n",
    "\n",
    "sql_query = f'''\n",
    "SELECT\n",
    "    \"bundleId\"\n",
    "FROM app_vectors\n",
    "ORDER BY embedding<=>'{json.dumps(vec)}'\n",
    "'''\n",
    "with engine.connect() as db_con:\n",
    "    df = pd.read_sql(sql_query, con=db_con)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7be478",
   "metadata": {},
   "source": [
    "# What you need to do\n",
    "## The hypothesis\n",
    "We assume that apps with similar desciptions, would have a similar asking price in the auctions (`sentPrice` column).\n",
    "\n",
    "Use cosine similarity (`<=>`) on the embeddings to find similar apps, and any statistical tools you find suitable to prove or disprove this hypothesis.\n",
    "\n",
    "## Is it consistent?\n",
    "There are several other features in the auctions table (such as `CountryCode` and `OS`), \n",
    "Do your findings hold for those as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b61a69-83f0-4325-aeb7-9c0bfe70a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Please write your analysis here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16441dee",
   "metadata": {},
   "source": [
    "# Solution <br>\n",
    "### 1. We need to find a way to quantify how good this way of searching is. <br>\n",
    "Lets calculate the correlation coefficient between cosine scores and price differences, then we can check if the correlation is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af74308",
   "metadata": {},
   "source": [
    "### 1.1 Correlation between the cosine similarity score of an app with its most similar app, and the price difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def statistical_tests_v1():\n",
    "    ids = embeds_df['id'].to_list()\n",
    "    most_similar_app_id = get_similar_app_id(ids) # {app_id: most_similar_app_id}\n",
    "    most_similar_app_score = get_similar_app_score(ids) # {app_id: most_similar_app_cosine_score}\n",
    "    price_difference = get_price_difference(most_similar_app_id) # {app_id: price_difference_with_most_similar_app}\n",
    "    assert list(most_similar_app_id.keys()) == list(price_difference.keys()), 'ids are in a different order'\n",
    "    \n",
    "    # Pearson\n",
    "    corr_coeff, p_value = pearsonr(list(most_similar_app_score.values()), list(price_difference.values()))\n",
    "    print(\"Pearson correlation coefficient:\", corr_coeff)\n",
    "    print(\"P-value:\", p_value)\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"The correlation is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(\"The correlation is not statistically significant.\\n\")\n",
    "\n",
    "    return list(most_similar_app_score.values()), list(price_difference.values())\n",
    "\n",
    "def get_similar_app_id(ids):\n",
    "    most_similar_app_id = {_id: get_most_similar(_id, ids)[0] for _id in ids}\n",
    "    return most_similar_app_id\n",
    "\n",
    "def get_similar_app_score(ids):\n",
    "    most_similar_app_score = {_id: get_most_similar(_id, ids)[1] for _id in ids}\n",
    "    return most_similar_app_score\n",
    "\n",
    "def get_most_similar(_id, ids):\n",
    "    app_embeds = embeds_df[embeds_df['id'] == _id]['embedding'].item()\n",
    "    other_apps_embeds = {other_app_id: embeds_df[embeds_df['id'] == other_app_id]['embedding'].item() for other_app_id in ids if other_app_id != _id}\n",
    "    max_score = np.NINF\n",
    "    most_similar_id = None\n",
    "    for other_app_id, other_app_embeds in other_apps_embeds.items():\n",
    "        cosine_score = cosine_similarity_score(app_embeds, other_app_embeds)\n",
    "        if cosine_score > max_score:\n",
    "            max_score = cosine_score\n",
    "            most_similar_id = other_app_id\n",
    "    return (most_similar_id, max_score)\n",
    "\n",
    "def cosine_similarity_score(vector1, vector2):\n",
    "    vector1 = json.loads(vector1)\n",
    "    vector2 = json.loads(vector2)\n",
    "    \n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "    return similarity\n",
    "\n",
    "def get_price_difference(most_similar_app_id):\n",
    "    price_difference = {}\n",
    "    for app_id, other_app_id in most_similar_app_id.items():\n",
    "        price_difference[app_id] = abs(big_df[big_df['id'] == app_id]['sentPrice'].item() - big_df[big_df['id'] == other_app_id]['sentPrice'].item())\n",
    "    return price_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims, diffs = statistical_tests_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ab9b0",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c54306",
   "metadata": {},
   "source": [
    "As there is'nt a lot of data (only 18 records in the app_vectors table), we can't really tell something here. We would expect that as the similarity gets higher, the differences in price will get smaller. As it can be seen this is not the case here, probably because of the small sample size. That's why we can try a different approach next, where we check not only for an app with it's most similar app, but with every other app and then calculate the correlation (we would have 18 * 17 = 306 records which is slightly better)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71939bf6",
   "metadata": {},
   "source": [
    "### 1.2 Correlation between the cosine similarity score of an app with every other app, and the price difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def statistical_tests_v2():\n",
    "    scores = {}\n",
    "    price_difference = {}\n",
    "    ids = embeds_df['id'].to_list()\n",
    "    for id1 in ids:\n",
    "        vec1 = embeds_df[embeds_df['id'] == id1]['embedding'].item()\n",
    "        for id2 in ids:\n",
    "            if id1 == id2:\n",
    "                continue\n",
    "            vec2 = embeds_df[embeds_df['id'] == id2]['embedding'].item()\n",
    "            scores[(id1, id2)] = cosine_similarity_score(vec1, vec2)\n",
    "            price_difference[(id1, id2)] = abs(big_df[big_df['id'] == id1]['sentPrice'].item() - big_df[big_df['id'] == id2]['sentPrice'].item())\n",
    "    assert list(scores.keys()) == list(price_difference.keys()), 'ids are in a different order'\n",
    "\n",
    "    # Pearson\n",
    "    corr_coeff, p_value = pearsonr(list(scores.values()), list(price_difference.values()))\n",
    "    print(\"Pearson correlation coefficient:\", corr_coeff)\n",
    "    print(\"P-value:\", p_value)\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\"The correlation is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(\"The correlation is not statistically significant.\\n\")\n",
    "\n",
    "    return (list(scores.values()), list(price_difference.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, diffs = statistical_tests_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08badaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(scores, diffs)\n",
    "\n",
    "plt.xlabel('scores')\n",
    "plt.ylabel('price diffs')\n",
    "\n",
    "z = np.polyfit(scores, diffs, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(scores,p(scores),\"r--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce4365",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974ce23",
   "metadata": {},
   "source": [
    "At a 95% confidence level, we fail to reject the null hypothesis, suggesting that the correlation observed is not statistically significant (we can see that it's negative as we would expect but it's small). However, at a 90% confidence level, we can reject the null hypothesis. Whether this finding is beneficial depends on our specific objectives and the error rate we can afford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b770cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fdd816a",
   "metadata": {},
   "source": [
    "### 2. Is it consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9661733",
   "metadata": {},
   "source": [
    "Intuitively, other features such as OS and CountryCode might provide more insightful comparisons between apps. For instance, applications with similar functionalities, alongside metrics like 'number of downloads,' could get us more meaningful insights. A similar number of downloads typically signifies a successful app, hence influencing a potentially higher sentPrice. To check this assumption, we can train a linear regression model. By inputting two apps with comparable features, we would expect observing a closer similarity in sentPrice values, thus affirming our hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
